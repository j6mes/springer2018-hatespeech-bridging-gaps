{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from dataset_reader import DataSet\n",
    "from features import features\n",
    "from preprocessing import preprocess\n",
    "from vocab import Vocab\n",
    "from composite_dataset import CompositeDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "racism = DataSet(\"racism_overlapfree\")\n",
    "sexism = DataSet(\"sexism_overlapfree\")\n",
    "neither = DataSet(\"neither_overlapfree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating features for racism: 100%|██████████| 1579/1579 [00:01<00:00, 1043.15it/s]\n",
      "Generating features for racism: 100%|██████████| 197/197 [00:00<00:00, 1131.41it/s]\n",
      "Generating features for racism: 100%|██████████| 198/198 [00:00<00:00, 1130.53it/s]\n",
      "Generating features for sexism: 100%|██████████| 2637/2637 [00:02<00:00, 1217.71it/s]\n",
      "Generating features for sexism: 100%|██████████| 330/330 [00:00<00:00, 1234.36it/s]\n",
      "Generating features for sexism: 100%|██████████| 330/330 [00:00<00:00, 1203.55it/s]\n",
      "Generating features for neither: 100%|██████████| 7008/7008 [00:05<00:00, 1289.77it/s]\n",
      "Generating features for neither: 100%|██████████| 876/876 [00:00<00:00, 1323.04it/s]\n",
      "Generating features for neither: 100%|██████████| 876/876 [00:00<00:00, 1171.96it/s]\n",
      "100%|██████████| 2637/2637 [00:00<00:00, 7299.66it/s]\n",
      "100%|██████████| 7008/7008 [00:00<00:00, 8311.76it/s]\n",
      "100%|██████████| 1579/1579 [00:00<00:00, 6196.05it/s]\n"
     ]
    }
   ],
   "source": [
    "data = CompositeDataset()\n",
    "data.add_data('racism',racism)\n",
    "data.add_data('sexism',sexism)\n",
    "data.add_data('neither',neither)\n",
    "\n",
    "train,dev,test,vocab = data.get_as_labelled()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def onehot(vals):\n",
    "    return (np.arange(num_classes)[:]==np.array(vals)[:,None]).astype(np.float32)\n",
    "\n",
    "def bow(vals,vocab):\n",
    "    vals = list(vals)\n",
    "    arr = np.zeros((len(vals),num_feats))\n",
    "    \n",
    "    for idx,val in enumerate(vals):\n",
    "        for key in val.keys():\n",
    "            arr[idx,key] = val[key]\n",
    "    \n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_classes = len(data.labels)\n",
    "num_feats = len(vocab.vocab)\n",
    "\n",
    "X_train,y_train = map(list,zip(*train))\n",
    "X_dev,y_dev = map(list,zip(*dev))\n",
    "X_test,y_test = map(list,zip(*test))\n",
    "\n",
    "y_train = onehot(y_train) \n",
    "y_dev = onehot(y_dev)\n",
    "y_test = onehot(y_test)\n",
    "\n",
    "X_train = bow(map(vocab.lookup,X_train),vocab)\n",
    "X_dev = bow(map(vocab.lookup,X_dev),vocab)\n",
    "X_test = bow(map(vocab.lookup,X_test),vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "l2_lambda = 1e-3\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "    global_step = tf.Variable(0)\n",
    "    learning_rate = tf.train.exponential_decay(0.5, global_step, 1000,0.8)\n",
    "\n",
    "    train_data = tf.placeholder(tf.float32, [batch_size,num_feats])\n",
    "    train_labels = tf.placeholder(tf.float32, [batch_size, num_classes])\n",
    "    \n",
    "    dev_data = tf.constant(X_dev.astype(np.float32))\n",
    "    test_data = tf.constant(X_test.astype(np.float32))\n",
    "    \n",
    "    weights1 = tf.Variable(tf.truncated_normal([num_feats, num_classes]))\n",
    "    biases1 = tf.Variable(tf.zeros([num_classes]))\n",
    "    \n",
    "    logits = tf.add(tf.matmul(train_data,weights1),biases1)\n",
    "    \n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=train_labels, logits=logits)) + l2_lambda * (tf.nn.l2_loss(weights1) + tf.nn.l2_loss(biases1))\n",
    "        \n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss,global_step=global_step)\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    dev_prediction = tf.nn.softmax(tf.matmul(dev_data, weights1) + biases1)\n",
    "    test_prediction = tf.nn.softmax(tf.matmul(test_data, weights1) + biases1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "l2_lambda = 1e-3\n",
    "\n",
    "hidden_size = 20\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "    global_step = tf.Variable(0)\n",
    "    learning_rate = tf.train.exponential_decay(0.5, global_step, 1000,0.8)\n",
    "\n",
    "    train_data = tf.placeholder(tf.float32, [batch_size,num_feats])\n",
    "    train_labels = tf.placeholder(tf.float32, [batch_size, num_classes])\n",
    "    \n",
    "    dev_data = tf.constant(X_dev.astype(np.float32))\n",
    "    test_data = tf.constant(X_test.astype(np.float32))\n",
    "    \n",
    "    weights1 = tf.Variable(tf.truncated_normal([num_feats, hidden_size]))\n",
    "    biases1 = tf.Variable(tf.zeros([hidden_size]))\n",
    "    \n",
    "    weights2 = tf.Variable(tf.truncated_normal([hidden_size, num_classes]))\n",
    "    biases2 = tf.Variable(tf.zeros([num_classes]))\n",
    "    \n",
    "    layer1 = tf.nn.relu(tf.add(tf.matmul(train_data,weights1),biases1))\n",
    "    \n",
    "    logits = tf.add(tf.matmul(layer1,weights2),biases2)\n",
    "    \n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=train_labels, logits=logits)) + l2_lambda * (tf.nn.l2_loss(weights1) + tf.nn.l2_loss(biases1) + tf.nn.l2_loss(weights2) + tf.nn.l2_loss(biases2))\n",
    "        \n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss,global_step=global_step)\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    dev_prediction = tf.nn.softmax(tf.add(tf.matmul(tf.nn.relu(tf.add(tf.matmul(dev_data,weights1),biases1)),weights2),biases2))\n",
    "    test_prediction = tf.nn.softmax(tf.add(tf.matmul(tf.nn.relu(tf.add(tf.matmul(test_data,weights1),biases1)),weights2),biases2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6734\n",
      "Minibatch loss at step 0: 183.391434\n",
      "[1 1 1 1 0]\n",
      "Minibatch accuracy: 60.0%\n",
      "[1 1 1 ..., 1 1 1]\n",
      "VALIDATION accuracy: 59.8%\n",
      "Minibatch loss at step 100: 231.933746\n",
      "[1 1 1 1 1]\n",
      "Minibatch accuracy: 60.0%\n",
      "[1 1 1 ..., 1 1 1]\n",
      "VALIDATION accuracy: 61.8%\n",
      "Minibatch loss at step 200: 210.711670\n",
      "[1 1 1 1 1]\n",
      "Minibatch accuracy: 60.0%\n",
      "[1 1 1 ..., 1 1 1]\n",
      "VALIDATION accuracy: 62.3%\n",
      "Minibatch loss at step 300: 191.946609\n",
      "[1 1 1 1 1]\n",
      "Minibatch accuracy: 40.0%\n",
      "[1 1 1 ..., 1 1 1]\n",
      "VALIDATION accuracy: 62.4%\n",
      "Minibatch loss at step 400: 174.944931\n",
      "[1 1 1 1 1]\n",
      "Minibatch accuracy: 60.0%\n",
      "[1 1 1 ..., 1 1 1]\n",
      "VALIDATION accuracy: 62.4%\n",
      "Minibatch loss at step 500: 159.875366\n",
      "[1 1 1 1 1]\n",
      "Minibatch accuracy: 60.0%\n",
      "[1 1 1 ..., 1 1 1]\n",
      "VALIDATION accuracy: 62.4%\n",
      "Minibatch loss at step 600: 146.787231\n",
      "[1 1 1 1 1]\n",
      "Minibatch accuracy: 20.0%\n",
      "[1 1 1 ..., 1 1 1]\n",
      "VALIDATION accuracy: 62.4%\n",
      "Minibatch loss at step 700: 134.041473\n",
      "[1 1 1 1 1]\n",
      "Minibatch accuracy: 80.0%\n",
      "[1 1 1 ..., 1 1 1]\n",
      "VALIDATION accuracy: 62.4%\n",
      "Minibatch loss at step 800: 123.531433\n",
      "[1 1 1 1 1]\n",
      "Minibatch accuracy: 60.0%\n",
      "[1 1 1 ..., 1 1 1]\n",
      "VALIDATION accuracy: 62.4%\n",
      "Minibatch loss at step 900: 113.799759\n",
      "[1 1 1 1 1]\n",
      "Minibatch accuracy: 60.0%\n",
      "[1 1 1 ..., 1 1 1]\n",
      "VALIDATION accuracy: 62.4%\n",
      "Minibatch loss at step 1000: 104.694801\n",
      "[1 1 1 1 1]\n",
      "Minibatch accuracy: 80.0%\n",
      "[1 1 1 ..., 1 1 1]\n",
      "VALIDATION accuracy: 62.4%\n",
      "Minibatch loss at step 1100: 96.877296\n",
      "[1 1 1 1 1]\n",
      "Minibatch accuracy: 80.0%\n",
      "[1 1 1 ..., 1 1 1]\n",
      "VALIDATION accuracy: 62.4%\n",
      "Minibatch loss at step 1200: 90.476524\n",
      "[1 1 1 1 1]\n",
      "Minibatch accuracy: 20.0%\n",
      "[1 1 1 ..., 1 1 1]\n",
      "VALIDATION accuracy: 62.4%\n",
      "Minibatch loss at step 1300: 83.870270\n",
      "[1 1 1 1 1]\n",
      "Minibatch accuracy: 20.0%\n",
      "[1 1 1 ..., 1 1 1]\n",
      "VALIDATION accuracy: 62.4%\n",
      "Minibatch loss at step 1400: 77.956528\n",
      "[1 1 1 1 1]\n",
      "Minibatch accuracy: 40.0%\n",
      "[1 1 1 ..., 1 1 1]\n",
      "VALIDATION accuracy: 62.4%\n",
      "Minibatch loss at step 1500: 72.175133\n",
      "[1 1 1 1 1]\n",
      "Minibatch accuracy: 60.0%\n",
      "[1 1 1 ..., 1 1 1]\n",
      "VALIDATION accuracy: 62.4%\n",
      "Minibatch loss at step 1600: 67.389252\n",
      "[1 1 1 1 1]\n",
      "Minibatch accuracy: 60.0%\n",
      "[1 1 1 ..., 1 1 1]\n",
      "VALIDATION accuracy: 62.4%\n",
      "Minibatch loss at step 1700: 63.146965\n",
      "[1 1 1 1 1]\n",
      "Minibatch accuracy: 40.0%\n",
      "[1 1 1 ..., 1 1 1]\n",
      "VALIDATION accuracy: 62.4%\n",
      "Minibatch loss at step 1800: 58.586018\n",
      "[1 1 1 1 1]\n",
      "Minibatch accuracy: 80.0%\n",
      "[1 1 1 ..., 1 1 1]\n",
      "VALIDATION accuracy: 62.4%\n",
      "Minibatch loss at step 1900: 54.769493\n",
      "[1 1 1 1 1]\n",
      "Minibatch accuracy: 100.0%\n",
      "[1 1 1 ..., 1 1 1]\n",
      "VALIDATION accuracy: 62.4%\n",
      "Minibatch loss at step 2000: 51.496780\n",
      "[1 1 1 1 1]\n",
      "Minibatch accuracy: 80.0%\n",
      "[1 1 1 ..., 1 1 1]\n",
      "VALIDATION accuracy: 62.4%\n",
      "Minibatch loss at step 2100: 48.870396\n",
      "[1 1 1 1 1]\n",
      "Minibatch accuracy: 40.0%\n",
      "[1 1 1 ..., 1 1 1]\n",
      "VALIDATION accuracy: 62.4%\n",
      "Minibatch loss at step 2200: 45.216057\n",
      "[1 1 1 1 1]\n",
      "Minibatch accuracy: 100.0%\n",
      "[1 1 1 ..., 1 1 1]\n",
      "VALIDATION accuracy: 62.4%\n",
      "Minibatch loss at step 2300: 42.968979\n",
      "[1 1 1 1 1]\n",
      "Minibatch accuracy: 80.0%\n",
      "[1 1 1 ..., 1 1 1]\n",
      "VALIDATION accuracy: 62.4%\n",
      "Minibatch loss at step 2400: 41.052170\n",
      "[1 1 1 1 1]\n",
      "Minibatch accuracy: 40.0%\n",
      "[1 1 1 ..., 1 1 1]\n",
      "VALIDATION accuracy: 62.4%\n",
      "Minibatch loss at step 2500: 38.235432\n",
      "[1 1 1 1 1]\n",
      "Minibatch accuracy: 80.0%\n",
      "[1 1 1 ..., 1 1 1]\n",
      "VALIDATION accuracy: 62.4%\n",
      "Minibatch loss at step 2600: 36.345718\n",
      "[1 1 1 1 1]\n",
      "Minibatch accuracy: 60.0%\n",
      "[1 1 1 ..., 1 1 1]\n",
      "VALIDATION accuracy: 62.4%\n",
      "Minibatch loss at step 2700: 34.313641\n",
      "[1 1 1 1 1]\n",
      "Minibatch accuracy: 80.0%\n",
      "[1 1 1 ..., 1 1 1]\n",
      "VALIDATION accuracy: 62.4%\n",
      "Minibatch loss at step 2800: 32.743153\n",
      "[1 1 1 1 1]\n",
      "Minibatch accuracy: 60.0%\n",
      "[1 1 1 ..., 1 1 1]\n",
      "VALIDATION accuracy: 62.4%\n",
      "Minibatch loss at step 2900: 31.227068\n",
      "[1 1 1 1 1]\n",
      "Minibatch accuracy: 60.0%\n",
      "[1 1 1 ..., 1 1 1]\n",
      "VALIDATION accuracy: 62.4%\n",
      "Minibatch loss at step 3000: 29.613632\n",
      "[1 1 1 1 1]\n",
      "Minibatch accuracy: 60.0%\n",
      "[1 1 1 ..., 1 1 1]\n",
      "VALIDATION accuracy: 62.4%\n",
      "Minibatch loss at step 3100: 27.594158\n",
      "[1 1 1 1 1]\n",
      "Minibatch accuracy: 100.0%\n",
      "[1 1 1 ..., 1 1 1]\n",
      "VALIDATION accuracy: 62.4%\n",
      "Minibatch loss at step 3200: 27.061802\n",
      "[1 1 1 1 1]\n",
      "Minibatch accuracy: 40.0%\n",
      "[1 1 1 ..., 1 1 1]\n",
      "VALIDATION accuracy: 62.4%\n",
      "Minibatch loss at step 3300: 25.181421\n",
      "[1 1 1 1 1]\n",
      "Minibatch accuracy: 100.0%\n",
      "[1 1 1 ..., 1 1 1]\n",
      "VALIDATION accuracy: 62.4%\n",
      "Minibatch loss at step 3400: 24.187651\n",
      "[1 1 1 1 1]\n",
      "Minibatch accuracy: 80.0%\n",
      "[1 1 1 ..., 1 1 1]\n",
      "VALIDATION accuracy: 62.4%\n",
      "Minibatch loss at step 3500: 23.236244\n",
      "[1 1 1 1 1]\n",
      "Minibatch accuracy: 80.0%\n",
      "[1 1 1 ..., 1 1 1]\n",
      "VALIDATION accuracy: 62.4%\n",
      "Minibatch loss at step 3600: 22.638161\n",
      "[1 1 1 1 1]\n",
      "Minibatch accuracy: 40.0%\n",
      "[1 1 1 ..., 1 1 1]\n",
      "VALIDATION accuracy: 62.4%\n",
      "Minibatch loss at step 3700: 21.984444\n",
      "[1 1 1 1 1]\n",
      "Minibatch accuracy: 40.0%\n",
      "[1 1 1 ..., 1 1 1]\n",
      "VALIDATION accuracy: 62.4%\n",
      "Minibatch loss at step 3800: 20.463642\n",
      "[1 1 1 1 1]\n",
      "Minibatch accuracy: 60.0%\n",
      "[1 1 1 ..., 1 1 1]\n",
      "VALIDATION accuracy: 62.4%\n",
      "Minibatch loss at step 3900: 19.530775\n",
      "[1 1 1 1 1]\n",
      "Minibatch accuracy: 100.0%\n",
      "[1 1 1 ..., 1 1 1]\n",
      "VALIDATION accuracy: 62.4%\n",
      "Minibatch loss at step 4000: 18.532463\n",
      "[1 1 1 1 1]\n",
      "Minibatch accuracy: 100.0%\n",
      "[1 1 1 ..., 1 1 1]\n",
      "VALIDATION accuracy: 62.4%\n",
      "Minibatch loss at step 4100: 18.256870\n",
      "[1 1 1 1 1]\n",
      "Minibatch accuracy: 60.0%\n",
      "[1 1 1 ..., 1 1 1]\n",
      "VALIDATION accuracy: 62.4%\n",
      "Minibatch loss at step 4200: 17.978848\n",
      "[1 1 1 1 1]\n",
      "Minibatch accuracy: 40.0%\n",
      "[1 1 1 ..., 1 1 1]\n",
      "VALIDATION accuracy: 62.4%\n",
      "Minibatch loss at step 4300: 17.159548\n",
      "[1 1 1 1 1]\n",
      "Minibatch accuracy: 60.0%\n",
      "[1 1 1 ..., 1 1 1]\n",
      "VALIDATION accuracy: 62.4%\n",
      "Minibatch loss at step 4400: 16.502445\n",
      "[1 1 1 1 1]\n",
      "Minibatch accuracy: 60.0%\n",
      "[1 1 1 ..., 1 1 1]\n",
      "VALIDATION accuracy: 62.4%\n",
      "Minibatch loss at step 4500: 15.578423\n",
      "[1 1 1 1 1]\n",
      "Minibatch accuracy: 80.0%\n",
      "[1 1 1 ..., 1 1 1]\n",
      "VALIDATION accuracy: 62.4%\n",
      "Minibatch loss at step 4600: 15.507152\n",
      "[1 1 1 1 1]\n",
      "Minibatch accuracy: 40.0%\n",
      "[1 1 1 ..., 1 1 1]\n",
      "VALIDATION accuracy: 62.4%\n",
      "Minibatch loss at step 4700: 14.764350\n",
      "[1 1 1 1 1]\n",
      "Minibatch accuracy: 60.0%\n",
      "[1 1 1 ..., 1 1 1]\n",
      "VALIDATION accuracy: 62.4%\n",
      "Minibatch loss at step 4800: 14.499561\n",
      "[1 1 1 1 1]\n",
      "Minibatch accuracy: 40.0%\n",
      "[1 1 1 ..., 1 1 1]\n",
      "VALIDATION accuracy: 62.4%\n",
      "Minibatch loss at step 4900: 13.880630\n",
      "[1 1 1 1 1]\n",
      "Minibatch accuracy: 60.0%\n",
      "[1 1 1 ..., 1 1 1]\n",
      "VALIDATION accuracy: 62.4%\n",
      "Minibatch loss at step 5000: 13.492926\n",
      "[1 1 1 1 1]\n",
      "Minibatch accuracy: 60.0%\n",
      "[1 1 1 ..., 1 1 1]\n",
      "VALIDATION accuracy: 62.4%\n",
      "Minibatch loss at step 5100: 12.861481\n",
      "[1 1 1 1 1]\n",
      "Minibatch accuracy: 60.0%\n",
      "[1 1 1 ..., 1 1 1]\n",
      "VALIDATION accuracy: 62.4%\n",
      "Minibatch loss at step 5200: 12.406643\n",
      "[1 1 1 1 1]\n",
      "Minibatch accuracy: 80.0%\n",
      "[1 1 1 ..., 1 1 1]\n",
      "VALIDATION accuracy: 62.4%\n",
      "Minibatch loss at step 5300: 12.419110\n",
      "[1 1 1 1 1]\n",
      "Minibatch accuracy: 40.0%\n",
      "[1 1 1 ..., 1 1 1]\n",
      "VALIDATION accuracy: 62.4%\n",
      "Minibatch loss at step 5400: 12.025945\n",
      "[1 1 1 1 1]\n",
      "Minibatch accuracy: 60.0%\n",
      "[1 1 1 ..., 1 1 1]\n",
      "VALIDATION accuracy: 62.4%\n",
      "Minibatch loss at step 5500: 11.587462\n",
      "[1 1 1 1 1]\n",
      "Minibatch accuracy: 60.0%\n",
      "[1 1 1 ..., 1 1 1]\n",
      "VALIDATION accuracy: 62.4%\n",
      "Minibatch loss at step 5600: 11.652228\n",
      "[1 1 1 1 1]\n",
      "Minibatch accuracy: 40.0%\n",
      "[1 1 1 ..., 1 1 1]\n",
      "VALIDATION accuracy: 62.4%\n",
      "Minibatch loss at step 5700: 11.026707\n",
      "[1 1 1 1 1]\n",
      "Minibatch accuracy: 60.0%\n",
      "[1 1 1 ..., 1 1 1]\n",
      "VALIDATION accuracy: 62.4%\n",
      "Minibatch loss at step 5800: 10.901484\n",
      "[1 1 1 1 1]\n",
      "Minibatch accuracy: 60.0%\n",
      "[1 1 1 ..., 1 1 1]\n",
      "VALIDATION accuracy: 62.4%\n",
      "Minibatch loss at step 5900: 10.240766\n",
      "[1 1 1 1 1]\n",
      "Minibatch accuracy: 80.0%\n",
      "[1 1 1 ..., 1 1 1]\n",
      "VALIDATION accuracy: 62.4%\n",
      "Minibatch loss at step 6000: 9.768873\n",
      "[1 1 1 1 1]\n",
      "Minibatch accuracy: 100.0%\n",
      "[1 1 1 ..., 1 1 1]\n",
      "VALIDATION accuracy: 62.4%\n",
      "Minibatch loss at step 6100: 9.934341\n",
      "[1 1 1 1 1]\n",
      "Minibatch accuracy: 80.0%\n",
      "[1 1 1 ..., 1 1 1]\n",
      "VALIDATION accuracy: 62.4%\n",
      "Minibatch loss at step 6200: 9.667434\n",
      "[1 1 1 1 1]\n",
      "Minibatch accuracy: 80.0%\n",
      "[1 1 1 ..., 1 1 1]\n",
      "VALIDATION accuracy: 62.4%\n",
      "Minibatch loss at step 6300: 10.196245\n",
      "[1 1 1 1 1]\n",
      "Minibatch accuracy: 20.0%\n",
      "[1 1 1 ..., 1 1 1]\n",
      "VALIDATION accuracy: 62.4%\n",
      "Minibatch loss at step 6400: 9.142516\n",
      "[1 1 1 1 1]\n",
      "Minibatch accuracy: 80.0%\n",
      "[1 1 1 ..., 1 1 1]\n",
      "VALIDATION accuracy: 62.4%\n",
      "Minibatch loss at step 6500: 8.858195\n",
      "[1 1 1 1 1]\n",
      "Minibatch accuracy: 80.0%\n",
      "[1 1 1 ..., 1 1 1]\n",
      "VALIDATION accuracy: 62.4%\n",
      "Minibatch loss at step 6600: 8.758408\n",
      "[1 1 1 1 1]\n",
      "Minibatch accuracy: 80.0%\n",
      "[1 1 1 ..., 1 1 1]\n",
      "VALIDATION accuracy: 62.4%\n",
      "Minibatch loss at step 6700: 8.626282\n",
      "[1 1 1 1 1]\n",
      "Minibatch accuracy: 80.0%\n",
      "[1 1 1 ..., 1 1 1]\n",
      "VALIDATION accuracy: 62.4%\n",
      "[1 1 1 ..., 1 1 1]\n",
      "FINAL TEST accuracy: 62.4%\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "num_steps = y_train.shape[0]*num_epochs//batch_size\n",
    "print(num_steps)\n",
    "\n",
    "def accuracy(predictions, labels):\n",
    "    return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1)) / predictions.shape[0])\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    for step in range(num_steps):\n",
    "        offset = (step * batch_size) % (y_train.shape[0] - batch_size)\n",
    "        \n",
    "        batch_data = X_train[offset:(offset + batch_size)]\n",
    "        batch_labels = y_train[offset:(offset + batch_size), :]\n",
    "        \n",
    "        feed_dict = {train_data : batch_data, train_labels : batch_labels}\n",
    "        _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        \n",
    "        if step % 100 == 0:\n",
    "            print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "            print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "            \n",
    "            print(\"VALIDATION accuracy: %.1f%%\" % accuracy(dev_prediction.eval(), y_dev))\n",
    "    print(\"FINAL TEST accuracy: %.1f%%\" % accuracy(test_prediction.eval(), y_test))\n",
    "            \n",
    "            \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1579/1579 [00:01<00:00, 1124.63it/s]\n",
      "100%|██████████| 197/197 [00:00<00:00, 803.82it/s]\n",
      "100%|██████████| 198/198 [00:00<00:00, 956.36it/s]\n",
      "100%|██████████| 7008/7008 [00:05<00:00, 1389.32it/s]\n",
      "100%|██████████| 876/876 [00:00<00:00, 1352.16it/s]\n",
      "100%|██████████| 876/876 [00:00<00:00, 1296.17it/s]\n",
      "100%|██████████| 1579/1579 [00:00<00:00, 5987.71it/s]\n",
      "100%|██████████| 7008/7008 [00:00<00:00, 7949.67it/s]\n",
      "100%|██████████| 2637/2637 [00:02<00:00, 1131.25it/s]\n",
      "100%|██████████| 330/330 [00:00<00:00, 1150.21it/s]\n",
      "100%|██████████| 330/330 [00:00<00:00, 1211.97it/s]\n",
      "100%|██████████| 7008/7008 [00:05<00:00, 1336.43it/s]\n",
      "100%|██████████| 876/876 [00:00<00:00, 1402.25it/s]\n",
      "100%|██████████| 876/876 [00:00<00:00, 1399.97it/s]\n",
      "100%|██████████| 7008/7008 [00:00<00:00, 8265.41it/s]\n",
      "100%|██████████| 2637/2637 [00:00<00:00, 7111.67it/s]\n"
     ]
    }
   ],
   "source": [
    "racism_data = CompositeDataset()\n",
    "racism_data.add_data('racism',racism)\n",
    "racism_data.add_data('neither',neither)\n",
    "\n",
    "racism_train,racism_dev,racism_test,_ = racism_data.get_as_labelled()\n",
    "\n",
    "\n",
    "sexism_data = CompositeDataset()\n",
    "sexism_data.add_data('sexism',sexism)\n",
    "sexism_data.add_data('neither',neither)\n",
    "\n",
    "sexism_train,sexism_dev,sexism_test,_ = sexism_data.get_as_labelled()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "X_racism_train,y_racism_train = map(list,zip(*racism_train))\n",
    "y_racism_train = onehot(y_racism_train) \n",
    "\n",
    "X_sexism_train,y_sexism_train = map(list,zip(*sexism_train))\n",
    "y_sexism_train = onehot(y_sexism_train) \n",
    "\n",
    "X_racism_train = bow(map(vocab.lookup,X_racism_train),vocab)\n",
    "X_sexism_train = bow(map(vocab.lookup,X_sexism_train),vocab)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_racism_dev,y_racism_dev = map(list,zip(*racism_dev))\n",
    "y_racism_dev = onehot(y_racism_dev) \n",
    "\n",
    "X_sexism_dev,y_sexism_dev = map(list,zip(*sexism_dev))\n",
    "y_sexism_dev = onehot(y_sexism_dev) \n",
    "\n",
    "X_racism_dev = bow(map(vocab.lookup,X_racism_dev),vocab)\n",
    "X_sexism_dev = bow(map(vocab.lookup,X_sexism_dev),vocab)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_racism_test,y_racism_test = map(list,zip(*racism_test))\n",
    "y_racism_test = onehot(y_racism_test) \n",
    "\n",
    "X_sexism_test,y_sexism_test = map(list,zip(*sexism_test))\n",
    "y_sexism_test = onehot(y_sexism_test) \n",
    "\n",
    "X_racism_test = bow(map(vocab.lookup,X_racism_test),vocab)\n",
    "X_sexism_test = bow(map(vocab.lookup,X_sexism_test),vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "l2_lambda = 1e-3\n",
    "\n",
    "hidden_size = 20\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "    global_step = tf.Variable(0)\n",
    "    learning_rate = tf.train.exponential_decay(0.5, global_step, 1000,0.8)\n",
    "\n",
    "    train_data = tf.placeholder(tf.float32, [batch_size,num_feats])\n",
    "    train_labels_racism = tf.placeholder(tf.float32, [batch_size, 2])\n",
    "    train_labels_sexism = tf.placeholder(tf.float32, [batch_size, 2])\n",
    "    #train_labels_neither = tf.placeholder(tf.float32, [batch_size, 2])\n",
    "    \n",
    "    dev_racism_data = tf.constant(X_racism_dev.astype(np.float32))\n",
    "    test_racism_data = tf.constant(X_racism_test.astype(np.float32))\n",
    "    \n",
    "    \n",
    "    dev_sexism_data = tf.constant(X_sexism_dev.astype(np.float32))\n",
    "    test_sexism_data = tf.constant(X_sexism_test.astype(np.float32))\n",
    "    \n",
    "    \n",
    "    weights1 = tf.Variable(tf.truncated_normal([num_feats, hidden_size]))\n",
    "    biases1 = tf.Variable(tf.zeros([hidden_size]))\n",
    "    \n",
    "    weights_racism = tf.Variable(tf.truncated_normal([hidden_size, 2]))\n",
    "    biases_racism = tf.Variable(tf.zeros([2]))\n",
    "    \n",
    "    weights_sexism = tf.Variable(tf.truncated_normal([hidden_size, 2]))\n",
    "    biases_sexism = tf.Variable(tf.zeros([2]))\n",
    "    \n",
    "    weights_neither = tf.Variable(tf.truncated_normal([hidden_size, 2]))\n",
    "    biases_neither = tf.Variable(tf.zeros([2]))\n",
    "    \n",
    "    \n",
    "    layer1 = tf.nn.relu(tf.add(tf.matmul(train_data,weights1),biases1))\n",
    "    \n",
    "    racism_logits = tf.add(tf.matmul(layer1,weights_racism),biases_racism)\n",
    "    racism_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=train_labels_racism, logits=racism_logits)) + l2_lambda * (tf.nn.l2_loss(weights1) + tf.nn.l2_loss(biases1) + tf.nn.l2_loss(weights_racism) + tf.nn.l2_loss(biases_racism))\n",
    "    racism_optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(racism_loss,global_step=global_step)\n",
    "    \n",
    "    sexism_logits = tf.add(tf.matmul(layer1,weights_racism),biases_racism)\n",
    "    sexism_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=train_labels_sexism, logits=sexism_logits)) + l2_lambda * (tf.nn.l2_loss(weights1) + tf.nn.l2_loss(biases1) + tf.nn.l2_loss(weights_sexism) + tf.nn.l2_loss(biases_sexism))\n",
    "    sexism_optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(sexism_loss,global_step=global_step)\n",
    "    \n",
    "    #neither_logits = tf.add(tf.matmul(layer1,weights_neither),biases_neither)\n",
    "    #neither_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=train_labels_neither, logits=neither_logits)) + l2_lambda * (tf.nn.l2_loss(weights1) + tf.nn.l2_loss(biases1) + tf.nn.l2_loss(weights_neither) + tf.nn.l2_loss(biases_neither))\n",
    "    #neither_optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(neither_loss,global_step=global_step)\n",
    "    \n",
    "    racism_prediction = tf.nn.softmax(racism_logits)\n",
    "    sexism_prediction = tf.nn.softmax(sexism_logits)\n",
    "    #neither_prediction = tf.nn.softmax(neither_logits)\n",
    "    \n",
    "    dev_racism_prediction = tf.nn.softmax(tf.add(tf.matmul(tf.nn.relu(tf.add(tf.matmul(dev_racism_data,weights1),biases1)),weights_racism),biases_racism))\n",
    "    test_racism_prediction = tf.nn.softmax(tf.add(tf.matmul(tf.nn.relu(tf.add(tf.matmul(test_racism_data,weights1),biases1)),weights_racism),biases_racism))\n",
    "    \n",
    "    dev_sexism_prediction = tf.nn.softmax(tf.add(tf.matmul(tf.nn.relu(tf.add(tf.matmul(dev_sexism_data,weights1),biases1)),weights_sexism),biases_sexism))\n",
    "    test_sexism_prediction = tf.nn.softmax(tf.add(tf.matmul(tf.nn.relu(tf.add(tf.matmul(test_sexism_data,weights1),biases1)),weights_sexism),biases_sexism))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10939\n",
      "Racism Minibatch loss at step 0: 163.522842\n",
      "Racism Minibatch accuracy: 52.0%\n",
      "Racism VALIDATION accuracy: 81.6%\n",
      "Sexism Minibatch loss at step 1: 890.753296\n",
      "Sexism Minibatch accuracy: 50.0%\n",
      "Sexism VALIDATION accuracy: 68.8%\n",
      "Racism Minibatch loss at step 200: 127.539948\n",
      "Racism Minibatch accuracy: 18.0%\n",
      "Racism VALIDATION accuracy: 81.0%\n",
      "Sexism Minibatch loss at step 201: 127.037483\n",
      "Sexism Minibatch accuracy: 24.0%\n",
      "Sexism VALIDATION accuracy: 71.3%\n",
      "Racism Minibatch loss at step 400: 105.888023\n",
      "Racism Minibatch accuracy: 82.0%\n",
      "Racism VALIDATION accuracy: 81.3%\n",
      "Sexism Minibatch loss at step 401: 105.502602\n",
      "Sexism Minibatch accuracy: 26.0%\n",
      "Sexism VALIDATION accuracy: 71.6%\n",
      "Racism Minibatch loss at step 600: 88.683327\n",
      "Racism Minibatch accuracy: 78.0%\n",
      "Racism VALIDATION accuracy: 81.3%\n",
      "Sexism Minibatch loss at step 601: 88.328453\n",
      "Sexism Minibatch accuracy: 30.0%\n",
      "Sexism VALIDATION accuracy: 71.6%\n",
      "Racism Minibatch loss at step 800: 74.873283\n",
      "Racism Minibatch accuracy: 70.0%\n",
      "Racism VALIDATION accuracy: 81.4%\n",
      "Sexism Minibatch loss at step 801: 74.560936\n",
      "Sexism Minibatch accuracy: 24.0%\n",
      "Sexism VALIDATION accuracy: 71.6%\n",
      "Racism Minibatch loss at step 1000: 63.728302\n",
      "Racism Minibatch accuracy: 76.0%\n",
      "Racism VALIDATION accuracy: 81.3%\n",
      "Sexism Minibatch loss at step 1001: 63.394150\n",
      "Sexism Minibatch accuracy: 32.0%\n",
      "Sexism VALIDATION accuracy: 71.7%\n",
      "Racism Minibatch loss at step 1200: 54.607861\n",
      "Racism Minibatch accuracy: 76.0%\n",
      "Racism VALIDATION accuracy: 81.5%\n",
      "Sexism Minibatch loss at step 1201: 54.373951\n",
      "Sexism Minibatch accuracy: 18.0%\n",
      "Sexism VALIDATION accuracy: 71.7%\n",
      "Racism Minibatch loss at step 1400: 47.145309\n",
      "Racism Minibatch accuracy: 18.0%\n",
      "Racism VALIDATION accuracy: 81.3%\n",
      "Sexism Minibatch loss at step 1401: 46.875404\n",
      "Sexism Minibatch accuracy: 26.0%\n",
      "Sexism VALIDATION accuracy: 71.8%\n",
      "Racism Minibatch loss at step 1600: 40.959389\n",
      "Racism Minibatch accuracy: 80.0%\n",
      "Racism VALIDATION accuracy: 81.3%\n",
      "Sexism Minibatch loss at step 1601: 40.728039\n",
      "Sexism Minibatch accuracy: 26.0%\n",
      "Sexism VALIDATION accuracy: 71.8%\n",
      "Racism Minibatch loss at step 1800: 35.820107\n",
      "Racism Minibatch accuracy: 72.0%\n",
      "Racism VALIDATION accuracy: 81.3%\n",
      "Sexism Minibatch loss at step 1801: 35.587952\n",
      "Sexism Minibatch accuracy: 32.0%\n",
      "Sexism VALIDATION accuracy: 71.8%\n",
      "Racism Minibatch loss at step 2000: 31.506834\n",
      "Racism Minibatch accuracy: 86.0%\n",
      "Racism VALIDATION accuracy: 81.5%\n",
      "Sexism Minibatch loss at step 2001: 31.332518\n",
      "Sexism Minibatch accuracy: 34.0%\n",
      "Sexism VALIDATION accuracy: 71.8%\n",
      "Racism Minibatch loss at step 2200: 27.906305\n",
      "Racism Minibatch accuracy: 86.0%\n",
      "Racism VALIDATION accuracy: 81.5%\n",
      "Sexism Minibatch loss at step 2201: 27.760445\n",
      "Sexism Minibatch accuracy: 22.0%\n",
      "Sexism VALIDATION accuracy: 71.8%\n",
      "Racism Minibatch loss at step 2400: 24.783737\n",
      "Racism Minibatch accuracy: 90.0%\n",
      "Racism VALIDATION accuracy: 81.5%\n",
      "Sexism Minibatch loss at step 2401: 24.747511\n",
      "Sexism Minibatch accuracy: 26.0%\n",
      "Sexism VALIDATION accuracy: 71.8%\n",
      "Racism Minibatch loss at step 2600: 22.202059\n",
      "Racism Minibatch accuracy: 88.0%\n",
      "Racism VALIDATION accuracy: 81.5%\n",
      "Sexism Minibatch loss at step 2601: 22.123352\n",
      "Sexism Minibatch accuracy: 30.0%\n",
      "Sexism VALIDATION accuracy: 71.8%\n",
      "Racism Minibatch loss at step 2800: 20.022018\n",
      "Racism Minibatch accuracy: 78.0%\n",
      "Racism VALIDATION accuracy: 81.4%\n",
      "Sexism Minibatch loss at step 2801: 19.867386\n",
      "Sexism Minibatch accuracy: 28.0%\n",
      "Sexism VALIDATION accuracy: 71.8%\n",
      "Racism Minibatch loss at step 3000: 18.052551\n",
      "Racism Minibatch accuracy: 78.0%\n",
      "Racism VALIDATION accuracy: 81.5%\n",
      "Sexism Minibatch loss at step 3001: 18.011568\n",
      "Sexism Minibatch accuracy: 30.0%\n",
      "Sexism VALIDATION accuracy: 71.8%\n",
      "Racism Minibatch loss at step 3200: 16.452164\n",
      "Racism Minibatch accuracy: 76.0%\n",
      "Racism VALIDATION accuracy: 81.5%\n",
      "Sexism Minibatch loss at step 3201: 16.324593\n",
      "Sexism Minibatch accuracy: 26.0%\n",
      "Sexism VALIDATION accuracy: 71.8%\n",
      "Racism Minibatch loss at step 3400: 14.986868\n",
      "Racism Minibatch accuracy: 88.0%\n",
      "Racism VALIDATION accuracy: 81.5%\n",
      "Sexism Minibatch loss at step 3401: 14.943237\n",
      "Sexism Minibatch accuracy: 24.0%\n",
      "Sexism VALIDATION accuracy: 71.8%\n",
      "Racism Minibatch loss at step 3600: 13.751655\n",
      "Racism Minibatch accuracy: 84.0%\n",
      "Racism VALIDATION accuracy: 81.5%\n",
      "Sexism Minibatch loss at step 3601: 13.691134\n",
      "Sexism Minibatch accuracy: 22.0%\n",
      "Sexism VALIDATION accuracy: 71.8%\n",
      "Racism Minibatch loss at step 3800: 12.636794\n",
      "Racism Minibatch accuracy: 92.0%\n",
      "Racism VALIDATION accuracy: 81.5%\n",
      "Sexism Minibatch loss at step 3801: 12.610010\n",
      "Sexism Minibatch accuracy: 30.0%\n",
      "Sexism VALIDATION accuracy: 71.8%\n",
      "Racism Minibatch loss at step 4000: 11.702904\n",
      "Racism Minibatch accuracy: 80.0%\n",
      "Racism VALIDATION accuracy: 81.5%\n",
      "Sexism Minibatch loss at step 4001: 11.635973\n",
      "Sexism Minibatch accuracy: 28.0%\n",
      "Sexism VALIDATION accuracy: 71.8%\n",
      "Racism Minibatch loss at step 4200: 10.859115\n",
      "Racism Minibatch accuracy: 80.0%\n",
      "Racism VALIDATION accuracy: 81.5%\n",
      "Sexism Minibatch loss at step 4201: 10.795712\n",
      "Sexism Minibatch accuracy: 28.0%\n",
      "Sexism VALIDATION accuracy: 71.8%\n",
      "Racism Minibatch loss at step 4400: 10.099764\n",
      "Racism Minibatch accuracy: 86.0%\n",
      "Racism VALIDATION accuracy: 81.5%\n",
      "Sexism Minibatch loss at step 4401: 10.082685\n",
      "Sexism Minibatch accuracy: 20.0%\n",
      "Sexism VALIDATION accuracy: 71.8%\n",
      "Racism Minibatch loss at step 4600: 9.414907\n",
      "Racism Minibatch accuracy: 92.0%\n",
      "Racism VALIDATION accuracy: 81.5%\n",
      "Sexism Minibatch loss at step 4601: 9.432529\n",
      "Sexism Minibatch accuracy: 24.0%\n",
      "Sexism VALIDATION accuracy: 71.8%\n",
      "Racism Minibatch loss at step 4800: 8.843075\n",
      "Racism Minibatch accuracy: 74.0%\n",
      "Racism VALIDATION accuracy: 81.5%\n",
      "Sexism Minibatch loss at step 4801: 8.822835\n",
      "Sexism Minibatch accuracy: 30.0%\n",
      "Sexism VALIDATION accuracy: 71.8%\n",
      "Racism Minibatch loss at step 5000: 8.275685\n",
      "Racism Minibatch accuracy: 84.0%\n",
      "Racism VALIDATION accuracy: 81.5%\n",
      "Sexism Minibatch loss at step 5001: 8.304336\n",
      "Sexism Minibatch accuracy: 36.0%\n",
      "Sexism VALIDATION accuracy: 71.8%\n",
      "Racism Minibatch loss at step 5200: 7.853930\n",
      "Racism Minibatch accuracy: 88.0%\n",
      "Racism VALIDATION accuracy: 81.5%\n",
      "Sexism Minibatch loss at step 5201: 7.827095\n",
      "Sexism Minibatch accuracy: 24.0%\n",
      "Sexism VALIDATION accuracy: 71.8%\n",
      "Racism Minibatch loss at step 5400: 7.409875\n",
      "Racism Minibatch accuracy: 76.0%\n",
      "Racism VALIDATION accuracy: 81.5%\n",
      "Sexism Minibatch loss at step 5401: 7.393703\n",
      "Sexism Minibatch accuracy: 38.0%\n",
      "Sexism VALIDATION accuracy: 71.8%\n",
      "Racism Minibatch loss at step 5600: 7.046453\n",
      "Racism Minibatch accuracy: 72.0%\n",
      "Racism VALIDATION accuracy: 81.5%\n",
      "Sexism Minibatch loss at step 5601: 7.032794\n",
      "Sexism Minibatch accuracy: 24.0%\n",
      "Sexism VALIDATION accuracy: 71.8%\n",
      "Racism Minibatch loss at step 5800: 6.679901\n",
      "Racism Minibatch accuracy: 82.0%\n",
      "Racism VALIDATION accuracy: 81.5%\n",
      "Sexism Minibatch loss at step 5801: 6.713840\n",
      "Sexism Minibatch accuracy: 20.0%\n",
      "Sexism VALIDATION accuracy: 71.8%\n",
      "Racism Minibatch loss at step 6000: 6.417930\n",
      "Racism Minibatch accuracy: 76.0%\n",
      "Racism VALIDATION accuracy: 81.5%\n",
      "Sexism Minibatch loss at step 6001: 6.342038\n",
      "Sexism Minibatch accuracy: 22.0%\n",
      "Sexism VALIDATION accuracy: 71.8%\n",
      "Racism Minibatch loss at step 6200: 6.091433\n",
      "Racism Minibatch accuracy: 84.0%\n",
      "Racism VALIDATION accuracy: 81.5%\n",
      "Sexism Minibatch loss at step 6201: 6.078851\n",
      "Sexism Minibatch accuracy: 34.0%\n",
      "Sexism VALIDATION accuracy: 71.8%\n",
      "Racism Minibatch loss at step 6400: 5.850338\n",
      "Racism Minibatch accuracy: 84.0%\n",
      "Racism VALIDATION accuracy: 81.5%\n",
      "Sexism Minibatch loss at step 6401: 5.814984\n",
      "Sexism Minibatch accuracy: 32.0%\n",
      "Sexism VALIDATION accuracy: 71.8%\n",
      "Racism Minibatch loss at step 6600: 5.618797\n",
      "Racism Minibatch accuracy: 88.0%\n",
      "Racism VALIDATION accuracy: 81.5%\n",
      "Sexism Minibatch loss at step 6601: 5.582042\n",
      "Sexism Minibatch accuracy: 30.0%\n",
      "Sexism VALIDATION accuracy: 71.8%\n",
      "Racism Minibatch loss at step 6800: 5.400122\n",
      "Racism Minibatch accuracy: 84.0%\n",
      "Racism VALIDATION accuracy: 81.5%\n",
      "Sexism Minibatch loss at step 6801: 5.386382\n",
      "Sexism Minibatch accuracy: 20.0%\n",
      "Sexism VALIDATION accuracy: 71.8%\n",
      "Racism Minibatch loss at step 7000: 5.178731\n",
      "Racism Minibatch accuracy: 82.0%\n",
      "Racism VALIDATION accuracy: 81.5%\n",
      "Sexism Minibatch loss at step 7001: 5.199798\n",
      "Sexism Minibatch accuracy: 28.0%\n",
      "Sexism VALIDATION accuracy: 71.8%\n",
      "Racism Minibatch loss at step 7200: 5.019448\n",
      "Racism Minibatch accuracy: 82.0%\n",
      "Racism VALIDATION accuracy: 81.5%\n",
      "Sexism Minibatch loss at step 7201: 4.975532\n",
      "Sexism Minibatch accuracy: 44.0%\n",
      "Sexism VALIDATION accuracy: 71.8%\n",
      "Racism Minibatch loss at step 7400: 4.825473\n",
      "Racism Minibatch accuracy: 88.0%\n",
      "Racism VALIDATION accuracy: 81.5%\n",
      "Sexism Minibatch loss at step 7401: 4.865489\n",
      "Sexism Minibatch accuracy: 24.0%\n",
      "Sexism VALIDATION accuracy: 71.8%\n",
      "Racism Minibatch loss at step 7600: 4.699814\n",
      "Racism Minibatch accuracy: 76.0%\n",
      "Racism VALIDATION accuracy: 81.5%\n",
      "Sexism Minibatch loss at step 7601: 4.693304\n",
      "Sexism Minibatch accuracy: 26.0%\n",
      "Sexism VALIDATION accuracy: 71.8%\n",
      "Racism Minibatch loss at step 7800: 4.541039\n",
      "Racism Minibatch accuracy: 84.0%\n",
      "Racism VALIDATION accuracy: 81.5%\n",
      "Sexism Minibatch loss at step 7801: 4.567879\n",
      "Sexism Minibatch accuracy: 24.0%\n",
      "Sexism VALIDATION accuracy: 71.8%\n",
      "Racism Minibatch loss at step 8000: 4.410893\n",
      "Racism Minibatch accuracy: 90.0%\n",
      "Racism VALIDATION accuracy: 81.5%\n",
      "Sexism Minibatch loss at step 8001: 4.407208\n",
      "Sexism Minibatch accuracy: 38.0%\n",
      "Sexism VALIDATION accuracy: 71.8%\n",
      "Racism Minibatch loss at step 8200: 4.279178\n",
      "Racism Minibatch accuracy: 86.0%\n",
      "Racism VALIDATION accuracy: 81.5%\n",
      "Sexism Minibatch loss at step 8201: 4.313278\n",
      "Sexism Minibatch accuracy: 30.0%\n",
      "Sexism VALIDATION accuracy: 71.8%\n",
      "Racism Minibatch loss at step 8400: 4.197298\n",
      "Racism Minibatch accuracy: 82.0%\n",
      "Racism VALIDATION accuracy: 81.5%\n",
      "Sexism Minibatch loss at step 8401: 4.187268\n",
      "Sexism Minibatch accuracy: 28.0%\n",
      "Sexism VALIDATION accuracy: 71.8%\n",
      "Racism Minibatch loss at step 8600: 4.073610\n",
      "Racism Minibatch accuracy: 80.0%\n",
      "Racism VALIDATION accuracy: 81.5%\n",
      "Sexism Minibatch loss at step 8601: 4.113633\n",
      "Sexism Minibatch accuracy: 24.0%\n",
      "Sexism VALIDATION accuracy: 71.8%\n",
      "Racism Minibatch loss at step 8800: 3.985205\n",
      "Racism Minibatch accuracy: 84.0%\n",
      "Racism VALIDATION accuracy: 81.5%\n",
      "Sexism Minibatch loss at step 8801: 4.011837\n",
      "Sexism Minibatch accuracy: 20.0%\n",
      "Sexism VALIDATION accuracy: 71.8%\n",
      "Racism Minibatch loss at step 9000: 3.900719\n",
      "Racism Minibatch accuracy: 82.0%\n",
      "Racism VALIDATION accuracy: 81.5%\n",
      "Sexism Minibatch loss at step 9001: 3.895699\n",
      "Sexism Minibatch accuracy: 34.0%\n",
      "Sexism VALIDATION accuracy: 71.8%\n",
      "Racism Minibatch loss at step 9200: 3.800561\n",
      "Racism Minibatch accuracy: 86.0%\n",
      "Racism VALIDATION accuracy: 81.5%\n",
      "Sexism Minibatch loss at step 9201: 3.829881\n",
      "Sexism Minibatch accuracy: 30.0%\n",
      "Sexism VALIDATION accuracy: 71.8%\n",
      "Racism Minibatch loss at step 9400: 3.741918\n",
      "Racism Minibatch accuracy: 74.0%\n",
      "Racism VALIDATION accuracy: 81.5%\n",
      "Sexism Minibatch loss at step 9401: 3.759095\n",
      "Sexism Minibatch accuracy: 26.0%\n",
      "Sexism VALIDATION accuracy: 71.8%\n",
      "Racism Minibatch loss at step 9600: 3.640678\n",
      "Racism Minibatch accuracy: 82.0%\n",
      "Racism VALIDATION accuracy: 81.6%\n",
      "Sexism Minibatch loss at step 9601: 3.674535\n",
      "Sexism Minibatch accuracy: 38.0%\n",
      "Sexism VALIDATION accuracy: 71.8%\n",
      "Racism Minibatch loss at step 9800: 3.582226\n",
      "Racism Minibatch accuracy: 86.0%\n",
      "Racism VALIDATION accuracy: 81.5%\n",
      "Sexism Minibatch loss at step 9801: 3.614843\n",
      "Sexism Minibatch accuracy: 30.0%\n",
      "Sexism VALIDATION accuracy: 71.8%\n",
      "Racism Minibatch loss at step 10000: 3.513648\n",
      "Racism Minibatch accuracy: 84.0%\n",
      "Racism VALIDATION accuracy: 81.6%\n",
      "Sexism Minibatch loss at step 10001: 3.581945\n",
      "Sexism Minibatch accuracy: 20.0%\n",
      "Sexism VALIDATION accuracy: 71.8%\n",
      "Racism Minibatch loss at step 10200: 3.455342\n",
      "Racism Minibatch accuracy: 86.0%\n",
      "Racism VALIDATION accuracy: 81.6%\n",
      "Sexism Minibatch loss at step 10201: 3.492257\n",
      "Sexism Minibatch accuracy: 32.0%\n",
      "Sexism VALIDATION accuracy: 71.8%\n",
      "Racism Minibatch loss at step 10400: 3.406957\n",
      "Racism Minibatch accuracy: 78.0%\n",
      "Racism VALIDATION accuracy: 81.6%\n",
      "Sexism Minibatch loss at step 10401: 3.442879\n",
      "Sexism Minibatch accuracy: 32.0%\n",
      "Sexism VALIDATION accuracy: 71.8%\n",
      "Racism Minibatch loss at step 10600: 3.356152\n",
      "Racism Minibatch accuracy: 80.0%\n",
      "Racism VALIDATION accuracy: 81.6%\n",
      "Sexism Minibatch loss at step 10601: 3.413242\n",
      "Sexism Minibatch accuracy: 20.0%\n",
      "Sexism VALIDATION accuracy: 71.8%\n",
      "Racism Minibatch loss at step 10800: 3.316154\n",
      "Racism Minibatch accuracy: 84.0%\n",
      "Racism VALIDATION accuracy: 81.5%\n",
      "Sexism Minibatch loss at step 10801: 3.329704\n",
      "Sexism Minibatch accuracy: 30.0%\n",
      "Sexism VALIDATION accuracy: 71.8%\n",
      "FINAL Racism TEST accuracy: 81.6%\n",
      "FINAL Sexism TEST accuracy: 72.1%\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "num_steps = (y_racism_train.shape[0]+y_sexism_train.shape[0])*num_epochs//batch_size\n",
    "print(num_steps)\n",
    "\n",
    "def accuracy(predictions, labels):\n",
    "    return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1)) / predictions.shape[0])\n",
    "\n",
    "task = 0\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    \n",
    "    racism_step = 0\n",
    "    sexism_step = 0\n",
    "    for step in range(num_steps):\n",
    "        if task % 2 == 0:\n",
    "            #Racism\n",
    "            \n",
    "            offset = (racism_step * batch_size) % (y_racism_train.shape[0] - batch_size)\n",
    "            \n",
    "            batch_data = X_racism_train[offset:(offset + batch_size)]\n",
    "            batch_labels = y_racism_train[offset:(offset + batch_size), :]\n",
    "\n",
    "            feed_dict = {train_data : batch_data, train_labels_racism : batch_labels}\n",
    "            _, l, predictions = session.run([racism_optimizer, racism_loss, racism_prediction], feed_dict=feed_dict)\n",
    "   \n",
    "            if racism_step % 100 == 0:\n",
    "                print(\"Racism Minibatch loss at step %d: %f\" % (step, l))\n",
    "                print(\"Racism Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "\n",
    "                print(\"Racism VALIDATION accuracy: %.1f%%\" % accuracy(dev_racism_prediction.eval(), y_racism_dev))\n",
    "                \n",
    "            \n",
    "            racism_step+=1\n",
    "            \n",
    "        elif task %2 == 1:\n",
    "            #Sexism\n",
    "            \n",
    "            offset = (sexism_step * batch_size) % (y_sexism_train.shape[0] - batch_size)\n",
    "            \n",
    "            batch_data = X_sexism_train[offset:(offset + batch_size)]\n",
    "            batch_labels = y_sexism_train[offset:(offset + batch_size), :]\n",
    "\n",
    "            feed_dict = {train_data : batch_data, train_labels_sexism : batch_labels}\n",
    "            _, l, predictions = session.run([sexism_optimizer, sexism_loss, sexism_prediction], feed_dict=feed_dict)\n",
    "\n",
    "            if sexism_step % 100 == 0:\n",
    "                print(\"Sexism Minibatch loss at step %d: %f\" % (step, l))\n",
    "                print(\"Sexism Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "\n",
    "                print(\"Sexism VALIDATION accuracy: %.1f%%\" % accuracy(dev_sexism_prediction.eval(), y_sexism_dev))\n",
    "                \n",
    "            sexism_step+=1\n",
    "        \n",
    "        task += 1\n",
    "        \n",
    "        \n",
    "    print(\"FINAL Racism TEST accuracy: %.1f%%\" % accuracy(test_racism_prediction.eval(), y_racism_test))\n",
    "    print(\"FINAL Sexism TEST accuracy: %.1f%%\" % accuracy(test_sexism_prediction.eval(), y_sexism_test))\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
